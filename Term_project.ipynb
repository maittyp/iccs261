{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Project: Predicting EURO 2024\n",
    "\n",
    "### Goal: build a predictive model that predicts the outcomes of the EURO 2024 tournament for each game from the group stage down to the final. The ultimate question is who will win the tournament. \n",
    "\n",
    "### Main features:  venue, tournament, location, home team, away team, score\n",
    "\n",
    "#### Datasets: {https://www.kaggle.com/datasets/martj42/international-football-results-from-1872-to-2017, https://www.kaggle.com/datasets/cashncarry/fifaworldranking}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_with_confeds = pd.read_csv(\"results.csv\")\n",
    "results_with_confeds.replace({\"Czech Republic\": \"Czechia\"}, inplace=True)\n",
    "shootouts = pd.read_csv(\"shootouts.csv\")\n",
    "rankings = pd.read_csv(\"rankings.csv\")\n",
    "results_with_confeds['date'] = pd.to_datetime(results_with_confeds['date'])\n",
    "results_with_confeds.insert(5, \"score_diff\",results_with_confeds['home_score'] - results_with_confeds['away_score'])\n",
    "shootouts['date'] = pd.to_datetime(shootouts['date'])\n",
    "rankings['rank_date'] = pd.to_datetime(rankings['rank_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home vs away (venue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_neutral = results_with_confeds[results_with_confeds['neutral']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "sns.boxplot([non_neutral['home_score'], non_neutral['away_score']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that historically, on non-neutral venues, the home team scores more goals. This does not neccesraily mean the home team wins. Now, we'll see how many wins the home team gets compared to draws and losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wins_draws_losses(df):\n",
    "    return pd.Series([len(df[df['score_diff'] > 0]), len(df[df['score_diff'] == 0]), len(df[df['score_diff'] < 0])])\n",
    "\n",
    "\n",
    "d = wins_draws_losses(non_neutral)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "fig = d.plot(kind='bar')\n",
    "fig.set_xticklabels([\"Wins\", \"Draws\", \"Losses\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.title(\"Home team results in non-neutral venues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that the home team in non-neutral venues is more likely to win the match. This makes sense since the home crowd rallies behind their country and gives a massive boost and momentum. \n",
    "\n",
    "#### Now, we'll look more specifically into the EUROs. We'll explore how the host nation performs, as although the matches are classed as being in a natural venue, the competition still takes place in their own country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_nations = results_with_confeds[(results_with_confeds['home_team'] == results_with_confeds['country']) & (results_with_confeds['tournament'] == \"UEFA Euro\")]\n",
    "\n",
    "res = wins_draws_losses(host_nations)\n",
    "plt.figure(figsize=(7, 4))\n",
    "fig = res.plot(kind='bar')\n",
    "fig.set_xticklabels([\"Wins\", \"Draws\", \"Losses\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.title(\"Host nation performances in EUROs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that if we look at single games, host nations seem to be favored in the EUROs. However, this doesn't mean that they will neccesarily win the competition, since a single loss may mean getting knocked out of the competition completely. On the other hand, it is possible to recover from a group stage loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progression of teams\n",
    "\n",
    "#### Here, we'll look at how far a given team gets in the previous Euros. We can do that by simple counting. From 2016 onwards, there are 6 groups each consisting of 4 teams, there are $6\\cdot \\binom{4}{2}=36$ group stage matches. Then, $8$ round of 16 matches, $4$ quarter finals, $2$ semi finals, and $1$ final. For previous years, the format is a little bit different, and we can adjust to this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euro(year):\n",
    "    euro = results_with_confeds[(results_with_confeds['date'].dt.year == year) & (results_with_confeds['tournament']==\"UEFA Euro\")]\n",
    "    if year >= 2016:\n",
    "        stages = 36*[\"Group Stage\"] + 8*[\"Round of 16\"] + 4*[\"Quarter Finals\"] + 2*[\"Semi Finals\"] + 1*[\"Final\"]\n",
    "    elif year >= 1996:\n",
    "        stages = 24*[\"Group Stage\"] + 4*[\"Quarter Finals\"] + 2*[\"Semi Finals\"] + 1*[\"Final\"]\n",
    "    elif year > 1980:\n",
    "        stages = 12*[\"Group Stage\"] + 2*[\"Semi Finals\"] + 1*[\"Final\"]\n",
    "    elif year == 1980:\n",
    "        stages = 12*[\"Group Stage\"] + 1*[\"Third Place Playoff\"] + 1*[\"Final\"]\n",
    "    elif year == 1968:\n",
    "        stages = 2*[\"Semi Finals\"] + 1*[\"Third Place Playoff\"] + 2*[\"Final\"]\n",
    "    else:\n",
    "        stages = 2*[\"Semi Finals\"] + 1*[\"Third Place Playoff\"] + 1*[\"Final\"]\n",
    "    euro.insert(7, \"stage\", stages)\n",
    "    return euro\n",
    "\n",
    "def achievement(team, year):\n",
    "    t = get_euro(year)\n",
    "    return t.loc[(t['home_team'] == team) | (t['away_team']==team)].tail(1)['stage'].values[0]\n",
    "\n",
    "def winner(year):\n",
    "    if year == 1968:\n",
    "        return 'Italy'\n",
    "    t = get_euro(year)\n",
    "    f = t[t['stage']==\"Final\"]\n",
    "    match f['score_diff'].values[0]:\n",
    "        case n if n>0: return f['home_team'].values[0] \n",
    "        case n if n<0: return f['away_team'].values[0] \n",
    "        case n if n==0: return shootouts[shootouts['date']==f['date'].values[0]]['winner'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [1960, 1964, 1968, 1972, 1976, 1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2012, 2016, 2021]\n",
    "winners = [winner(year) for year in years]\n",
    "winners_new = list(set(winners))\n",
    "counts = [winners.count(year) for year in winners_new]\n",
    "li = sorted(list(zip(winners_new, counts)), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "labels = [e[0] for e in li]\n",
    "values = [e[1] for e in li]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.xticks(rotation=90)\n",
    "plt.bar(labels, values)\n",
    "plt.title(\"EURO Winners\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host Nation Progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def host_nation(year):\n",
    "    return results_with_confeds[(results_with_confeds['tournament'] == \"UEFA Euro\") & (results_with_confeds['date'].dt.year == year)].tail(1)['country'].values[0]\n",
    "\n",
    "years_except_2021 = [1960, 1964, 1968, 1972, 1976, 1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2012, 2016]\n",
    "\n",
    "progressions = [achievement(host_nation(year), year) for year in years_except_2021]\n",
    "\n",
    "progressions = list(map(lambda x: x.replace('Third Place Playoff', 'Semi Finals'), progressions))\n",
    "\n",
    "palette_color = sns.color_palette('bright') \n",
    "d = {i:progressions.count(i) for i in set(progressions)}\n",
    "\n",
    "plt.pie(x=d.values(), labels=d.keys(),colors=palette_color, autopct='%.0f%%') \n",
    "plt.title(\"Host Nation Progression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that historically, nations perform well when being backed up by a home crowd. 87% of host nations make it to the semi finals or further, although this is misleading as in the early years, teams progressed to the semi finals directly upon getting past the group stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including the team rankings and confederations into the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confeds = rankings.drop_duplicates(subset='country_full')[['country_full', 'confederation']]\n",
    "\n",
    "home_df = confeds.rename(columns={'country_full': 'home_team', 'confederation': 'home_confederation'})\n",
    "away_df = confeds.rename(columns={'country_full': 'away_team', 'confederation': 'away_confederation'})\n",
    "\n",
    "results_with_confeds = results_with_confeds.merge(home_df[['home_team', 'home_confederation']], on='home_team', how='left')\n",
    "results_with_confeds = results_with_confeds.merge(away_df[['away_team', 'away_confederation']], on='away_team', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = rankings.sort_values(by=['country_full', 'rank_date'])\n",
    "\n",
    "rankings_home = rankings.rename(columns={'country_full': 'home_team', 'rank': 'home_ranking', 'rank_date': 'home_ranking_date'})\n",
    "results_with_confeds = pd.merge_asof(results_with_confeds.sort_values('date'),\n",
    "                           rankings_home.sort_values('home_ranking_date'),\n",
    "                           left_on='date',\n",
    "                           right_on='home_ranking_date',\n",
    "                           by='home_team',\n",
    "                           direction='backward')\n",
    "\n",
    "rankings_away = rankings.rename(columns={'country_full': 'away_team', 'rank': 'away_ranking', 'rank_date': 'away_ranking_date'})\n",
    "results_with_confeds = pd.merge_asof(results_with_confeds.sort_values('date'),\n",
    "                           rankings_away.sort_values('away_ranking_date'),\n",
    "                           left_on='date',\n",
    "                           right_on='away_ranking_date',\n",
    "                           by='away_team',\n",
    "                           direction='backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_with_confeds.columns\n",
    "\n",
    "results_with_rankings = results_with_confeds.drop(columns=['country_abrv_x', 'total_points_x', 'previous_points_x',\n",
    "       'rank_change_x', 'confederation_x', 'home_ranking_date', 'country_abrv_y', 'total_points_y', 'previous_points_y',\n",
    "       'rank_change_y', 'confederation_y', 'away_ranking_date', 'city', 'country'])\n",
    "\n",
    "results_with_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro24 = results_with_rankings[(results_with_rankings['tournament']==\"UEFA Euro\") & (results_with_rankings['date'].dt.year==2024)].drop(\n",
    "    columns=['home_score', 'away_score', 'date', 'score_diff', 'home_confederation', 'away_confederation', 'tournament'])\n",
    "\n",
    "euro24.replace({False: 0, True: 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set 1: Predict $\\texttt{score\\_diff}$ (one feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_gd = results_with_rankings.dropna()\n",
    "with_gd = with_gd[(with_gd['home_confederation'] == \"UEFA\") & (with_gd['away_confederation'] == \"UEFA\")]\n",
    "with_gd.drop(columns=['home_team', 'away_team', 'date', 'home_confederation', 'away_confederation', 'tournament', 'home_score', 'away_score'], inplace=True)\n",
    "with_gd.replace({False: 0, True: 1}, inplace=True)\n",
    "\n",
    "with_gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_group_stages(model):\n",
    "    euro24_testing = euro24.drop(columns=[\"home_team\", \"away_team\"]).dropna()\n",
    "    pred_score_diffs = model.predict(euro24_testing)\n",
    "    rounded_preds = np.round(pred_score_diffs).astype(int)\n",
    "    group_stage = euro24.dropna().reset_index(drop=True)\n",
    "    groups = ['A', 'A', 'B', 'B', 'D', 'C', 'C', 'E', 'D', 'E', 'F', 'F', 'A', 'A', 'B', 'B', 'C', 'C',\n",
    "              'D', 'D', 'E', 'E', 'F', 'F', 'A', 'A', 'B', 'B', 'D', 'C', 'D', 'C', 'E', 'E', 'F', 'F']\n",
    "    group_stage.insert(2, \"group\", groups)\n",
    "    group_stage['score_diff'] = rounded_preds.flatten()\n",
    "    return group_stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1.0 (Baseline): Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = with_gd.drop('score_diff', axis=1)\n",
    "y = with_gd['score_diff']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model1_0 = LinearRegression()\n",
    "model1_0.fit(X_train, y_train)\n",
    "predictions = model1_0.predict(X_test)\n",
    "rounded_predictions = np.round(predictions).astype(int)\n",
    "mae = mean_absolute_error(y_test, rounded_predictions)\n",
    "mse = mean_squared_error(y_test, rounded_predictions)\n",
    "accuracy = np.mean(rounded_predictions.flatten() == y_test)\n",
    "\n",
    "mae, mse, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_group_stages(model1_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1.1: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model1_1 = RandomForestRegressor()\n",
    "model1_1.fit(X_train, y_train)\n",
    "predictions = model1_1.predict(X_test)\n",
    "rounded_predictions = np.round(predictions).astype(int)\n",
    "mae = mean_absolute_error(y_test, rounded_predictions)\n",
    "mse = mean_squared_error(y_test, rounded_predictions)\n",
    "accuracy = np.mean(rounded_predictions.flatten() == y_test)\n",
    "\n",
    "mae, mse, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1.2: Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model1_2 = Sequential()\n",
    "\n",
    "# First hidden layer with 64 neurons\n",
    "model1_2.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model1_2.add(BatchNormalization())  \n",
    "model1_2.add(Dropout(0.5))  \n",
    "\n",
    "# Second hidden layer with 64 neurons\n",
    "model1_2.add(Dense(64, activation='relu'))\n",
    "model1_2.add(BatchNormalization())\n",
    "model1_2.add(Dropout(0.5))\n",
    "\n",
    "# Third hidden layer with 32 neurons\n",
    "model1_2.add(Dense(32, activation='relu'))\n",
    "model1_2.add(BatchNormalization())\n",
    "model1_2.add(Dropout(0.5))\n",
    "\n",
    "model1_2.add(Dense(1, activation='linear'))\n",
    "\n",
    "model1_2.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "model1_2.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1)\n",
    "\n",
    "predictions = model1_2.predict(X_test)\n",
    "\n",
    "rounded_predictions = np.round(predictions).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean(rounded_predictions.flatten() == y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_group_stages(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set 3: Predicting both team's scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_3 = results_with_rankings.drop(columns=[\"home_team\", \"away_team\",\"date\", \"score_diff\", \"tournament\", \"home_confederation\", \"away_confederation\"]).dropna()\n",
    "\n",
    "set_3.replace({False: 0, True: 1}, inplace=True)\n",
    "\n",
    "set_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def pred_group_stages_multi(model):\n",
    "    group_stage = euro24.dropna().drop(columns=[\"home_team\", \"away_team\"]).reset_index(drop=True)\n",
    "    preds = np.round(model.predict(group_stage)).astype(int)\n",
    "    preds_df = pd.DataFrame(preds, columns=[\"home_score\", \"away_score\"]).reset_index(drop=True)\n",
    "    group_stage = pd.concat([euro24.dropna().reset_index(drop=True), preds_df], axis=1)\n",
    "    groups = ['A', 'A', 'B', 'B', 'D', 'C', 'C', 'E', 'D', 'E', 'F', 'F', 'A', 'A', 'B', 'B', 'C', 'C',\n",
    "              'D', 'D', 'E', 'E', 'F', 'F', 'A', 'A', 'B', 'B', 'D', 'C', 'D', 'C', 'E', 'E', 'F', 'F']\n",
    "    group_stage.insert(2, \"group\", groups)\n",
    "    return group_stage.drop(columns=[\"neutral\", \"home_ranking\", \"away_ranking\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3.1: MultiOutputRegressor with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = set_3.drop(columns=[\"home_score\", \"away_score\"])\n",
    "y = set_3[[\"home_score\", \"away_score\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "\n",
    "model3_1 = MultiOutputRegressor(LinearRegression())\n",
    "model3_1.fit(X_train, y_train)\n",
    "y_pred_lr = model3_1.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred_lr)\n",
    "\n",
    "pred_group_stages_multi(model3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3.2: MultiOutputRegressor with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "model3_2 = MultiOutputRegressor(RandomForestRegressor(n_estimators=200))\n",
    "model3_2.fit(X_train, y_train)\n",
    "y_pred = model3_2.predict(X_test)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "pred_group_stages_multi(model3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3.3: Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "model3_3 = Sequential([\n",
    "    Dense(64, input_dim=3, activation='relu'), \n",
    "    Dropout(0.2),  # Dropout layer for regularization\n",
    "    Dense(128, activation='relu'),  # First hidden layer\n",
    "    Dropout(0.2),  # Dropout layer for regularization\n",
    "    Dense(64, activation='relu'),  # Second hidden layer\n",
    "    Dense(32, activation='relu'),  # Third hidden layer\n",
    "    Dense(16, activation='relu'),  # Fourth hidden layer\n",
    "    Dense(2)  # Output layer with 2 neurons (for 2 continuous outcomes)\n",
    "])\n",
    "\n",
    "model3_3.compile(optimizer='adam', loss='mean_squared_error') \n",
    "model3_3.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)  # Validation split for monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_group_stages_multi(model3_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Stages\n",
    "\n",
    "#### After predicting each match of the group stage, we now calculate the group tables. The top two teams progress to the round of 16, along with the four best third place teams. The group table for each group A to F will be represented as a $\\texttt{dict\\{\\text{Team}: List[\\text{pts}, \\text{scored}, \\text{conceded}, \\text{difference}]\\}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_table(group, model):\n",
    "    predictions = pred_group_stages_multi(model)\n",
    "    groups = [dict(), dict(), dict(), dict(), dict(), dict()]\n",
    "    h2h = dict()\n",
    "    group_letters = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "    for index, row in predictions.iterrows():\n",
    "        ind = group_letters.index(row['group'])\n",
    "        dic = groups[ind]\n",
    "        home = row['home_team']\n",
    "        away = row['away_team']\n",
    "        home_score = row['home_score']\n",
    "        away_score = row['away_score']\n",
    "        if home not in dic.keys():\n",
    "            dic[home] = [0,0,0,0]\n",
    "        if away not in dic.keys():\n",
    "            dic[away] = [0,0,0,0]\n",
    "        if home not in h2h.keys():\n",
    "            h2h[home] = dict()\n",
    "        if away not in h2h.keys():\n",
    "            h2h[away] = dict()\n",
    "        if home_score > away_score:\n",
    "            diff = home_score - away_score\n",
    "            dic[home][0] += 3\n",
    "            dic[home][1] += home_score\n",
    "            dic[home][2] += away_score\n",
    "            dic[home][3] += diff\n",
    "            dic[away][1] += away_score\n",
    "            dic[away][2] += home_score\n",
    "            dic[away][3] -= diff\n",
    "            h2h[home][away] = 1\n",
    "            h2h[away][home] = 0\n",
    "        elif home_score == away_score:\n",
    "            dic[home][0] += 1\n",
    "            dic[home][1] += home_score\n",
    "            dic[home][2] += away_score\n",
    "            dic[away][0] += 1\n",
    "            dic[away][1] += away_score\n",
    "            dic[away][2] += home_score\n",
    "            h2h[home][away] = 0\n",
    "            h2h[away][home] = 0\n",
    "        else:\n",
    "            diff = away_score - home_score\n",
    "            dic[away][0] += 3\n",
    "            dic[away][1] += away_score\n",
    "            dic[away][2] += home_score\n",
    "            dic[away][3] += diff\n",
    "            dic[home][1] += home_score\n",
    "            dic[home][2] += away_score\n",
    "            dic[home][3] -= diff\n",
    "            h2h[home][away] = 0\n",
    "            h2h[away][home] = 1\n",
    "        groups[ind] = dic\n",
    "    ans = groups[group_letters.index(group)]\n",
    "    return dict(sorted(ans.items(), key=lambda x: (x[1][0], x[1][3], x[1][2]), reverse=True))\n",
    "\n",
    "def get_h2h(model):\n",
    "    predictions = pred_group_stages_multi(model)\n",
    "    h2h = dict()\n",
    "    for index, row in predictions.iterrows():\n",
    "        home = row['home_team']\n",
    "        away = row['away_team']\n",
    "        home_score = row['home_score']\n",
    "        away_score = row['away_score']\n",
    "        if home not in h2h.keys():\n",
    "            h2h[home] = dict()\n",
    "        if away not in h2h.keys():\n",
    "            h2h[away] = dict()\n",
    "        if home_score > away_score:\n",
    "            h2h[home][away] = 1\n",
    "            h2h[away][home] = 0\n",
    "        elif home_score == away_score:\n",
    "            h2h[home][away] = 0\n",
    "            h2h[away][home] = 0\n",
    "        else:\n",
    "            h2h[home][away] = 0\n",
    "            h2h[away][home] = 1\n",
    "    return h2h\n",
    "\n",
    "get_group_table('E', model3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the bracket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](euro-2024-bracket.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round of 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent_ranking(country):\n",
    "    return rankings[rankings['country_full']==country].tail(1)['rank'].values[0]\n",
    "\n",
    "def group_winner(group, model):\n",
    "    group_tbl = list(get_group_table(group, model))\n",
    "    return group_tbl[0]\n",
    "\n",
    "def runner_up(group, model):\n",
    "    group_tbl = list(get_group_table(group, model))\n",
    "    return group_tbl[1]\n",
    "\n",
    "def third_place_teams(model):\n",
    "    third_places = dict()\n",
    "    for group in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]:\n",
    "        (key, value) = list(get_group_table(group, model).items())[2]\n",
    "        third_places[key] = (value, group)\n",
    "    return dict(sorted(third_places.items(), key=lambda x: (x[1][0][0], x[1][0][3], x[1][0][2]), reverse=True))\n",
    "\n",
    "def third_place_slot(third_place, possible_groups):\n",
    "    for key in third_place:\n",
    "        if third_place[key][1] in possible_groups:\n",
    "            return key, third_place[key][1]\n",
    "        \n",
    "def get_neutral(row):\n",
    "    if row['home_team'] == \"Germany\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def forced_home_adv(x):\n",
    "    return (x != \"Germany\", x)\n",
    "\n",
    "def home_rankings(row):\n",
    "    return get_recent_ranking(row['home_team'])\n",
    "\n",
    "def away_rankings(row): \n",
    "    return get_recent_ranking(row['away_team'])\n",
    "\n",
    "def get_r16(model):\n",
    "    third_places = third_place_teams(model)\n",
    "    r16 = pd.DataFrame(columns=[\"home_team\", \"away_team\"])\n",
    "    third_ADEF = third_place_slot(third_places, [\"A\", \"D\", \"E\", \"F\"])[0]\n",
    "    del third_places[third_ADEF]\n",
    "    third_ABC = third_place_slot(third_places, [\"A\", \"B\", \"C\"])[0]\n",
    "    del third_places[third_ABC]\n",
    "    third_ABCD = third_place_slot(third_places, [\"A\", \"B\", \"C\", \"D\"])[0]\n",
    "    del third_places[third_ABCD]\n",
    "    third_DEF = third_place_slot(third_places, [\"D\", \"E\", \"F\"])[0]\n",
    "    del third_places[third_DEF]\n",
    "    r16.loc[0] = sorted([group_winner(\"B\", model), third_ADEF], key=forced_home_adv)\n",
    "    r16.loc[1] = sorted([group_winner(\"A\", model), runner_up(\"C\", model)], key=forced_home_adv)\n",
    "    r16.loc[2] = [group_winner(\"F\", model), third_ABC]\n",
    "    r16.loc[3] = [runner_up(\"D\", model), runner_up(\"E\", model)]\n",
    "    r16.loc[4] = [group_winner(\"E\", model), third_ABCD]\n",
    "    r16.loc[5] = [group_winner(\"D\", model), runner_up(\"F\", model)]\n",
    "    r16.loc[6] = [group_winner(\"C\", model), third_DEF]\n",
    "    r16.loc[7] = [runner_up(\"A\", model), runner_up(\"B\", model)]\n",
    "    r16['neutral'] = r16.apply(get_neutral, axis=1)\n",
    "    r16['home_ranking'] = r16.apply(home_rankings, axis=1)\n",
    "    r16['away_ranking'] = r16.apply(away_rankings, axis=1)\n",
    "    return r16\n",
    "\n",
    "get_r16(model3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting penalty shootouts as a tiebreaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = rankings.sort_values(by=['country_full', 'rank_date'])\n",
    "\n",
    "rankings_home = rankings.rename(columns={'country_full': 'home_team', 'rank': 'home_ranking', 'rank_date': 'home_ranking_date'})\n",
    "\n",
    "shootouts_with_rankings = pd.merge_asof(shootouts.sort_values('date'),\n",
    "                           rankings_home.sort_values('home_ranking_date'),\n",
    "                           left_on='date',\n",
    "                           right_on='home_ranking_date',\n",
    "                           by='home_team',\n",
    "                           direction='backward')\n",
    "\n",
    "rankings_away = rankings.rename(columns={'country_full': 'away_team', 'rank': 'away_ranking', 'rank_date': 'away_ranking_date'})\n",
    "\n",
    "shootouts_with_rankings = pd.merge_asof(shootouts_with_rankings.sort_values('date'),\n",
    "                           rankings_away.sort_values('away_ranking_date'),\n",
    "                           left_on='date',\n",
    "                           right_on='away_ranking_date',\n",
    "                           by='away_team',\n",
    "                           direction='backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shootouts_with_rankings.drop(columns=['country_abrv_x', 'total_points_x', 'previous_points_x',\n",
    "       'rank_change_x', 'confederation_x', 'home_ranking_date', 'country_abrv_y', 'total_points_y', 'previous_points_y',\n",
    "       'rank_change_y', 'confederation_y', 'away_ranking_date'], inplace=True)\n",
    "\n",
    "shootouts_with_rankings = shootouts_with_rankings.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shootouts_with_rankings.loc[shootouts_with_rankings['winner'] == shootouts_with_rankings['home_team'], 'winner_01'] = 1\n",
    "shootouts_with_rankings.loc[shootouts_with_rankings['winner'] == shootouts_with_rankings['away_team'], 'winner_01'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "shootout_training = shootouts_with_rankings.iloc[:, -3:]\n",
    "X = shootout_training.drop('winner_01', axis=1)\n",
    "y = shootout_training['winner_01']\n",
    "\n",
    "n_trials = 500\n",
    "best_accuracy = 0\n",
    "best_so_model = None\n",
    "\n",
    "for i in range(n_trials):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc\n",
    "        best_so_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quarters(model):\n",
    "    r16 = get_r16(model)\n",
    "    r16_train = r16.drop(columns=['home_team', 'away_team'])\n",
    "    \n",
    "    r16_preds = np.round(model.predict(r16_train)).astype(int)\n",
    "    r16_preds_df = pd.DataFrame(r16_preds, columns=[\"home_score\", \"away_score\"]).reset_index(drop=True)\n",
    "    \n",
    "    r16_results = pd.concat([r16.reset_index(drop=True), r16_preds_df], axis=1)\n",
    "\n",
    "    shootout_preds = best_model.predict(r16.drop(columns=['home_team', 'away_team', 'neutral']))\n",
    "\n",
    "    r16_results['winner'] = shootout_preds\n",
    "    \n",
    "    r16_results.loc[r16_results['home_score'] > r16_results['away_score'], 'winner'] = r16_results['home_team']\n",
    "    r16_results.loc[r16_results['home_score'] < r16_results['away_score'], 'winner'] = r16_results['away_team']\n",
    "    r16_results.loc[r16_results['winner'] == 1, 'winner'] = r16_results['home_team']\n",
    "    r16_results.loc[r16_results['winner'] == 0, 'winner'] = r16_results['away_team']\n",
    "\n",
    "    winners = list(r16_results['winner'])\n",
    "    quarters = pd.DataFrame(columns=[\"home_team\", \"away_team\"])\n",
    "    \n",
    "    quarters.loc[0] = sorted([winners[0], winners[1]], key=forced_home_adv)\n",
    "    quarters.loc[1] = sorted([winners[2], winners[3]], key=forced_home_adv)\n",
    "    quarters.loc[2] = sorted([winners[4], winners[5]], key=forced_home_adv)\n",
    "    quarters.loc[3] = sorted([winners[6], winners[7]], key=forced_home_adv)\n",
    "    \n",
    "    quarters['neutral'] = quarters.apply(get_neutral, axis=1)\n",
    "    quarters['home_ranking'] = quarters.apply(home_rankings, axis=1)\n",
    "    quarters['away_ranking'] = quarters.apply(away_rankings, axis=1)\n",
    "    \n",
    "    return quarters\n",
    "\n",
    "get_quarters(model3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semis(model):\n",
    "    quarters = get_quarters(model)\n",
    "    \n",
    "    quarters_train = quarters.drop(columns=['home_team', 'away_team'])\n",
    "    \n",
    "    preds = np.round(model.predict(quarters_train)).astype(int)\n",
    "    preds_df = pd.DataFrame(preds, columns=[\"home_score\", \"away_score\"]).reset_index(drop=True)\n",
    "    \n",
    "    quarters_results = pd.concat([quarters.reset_index(drop=True), preds_df], axis=1)\n",
    "\n",
    "    shootout_preds = best_model.predict(quarters.drop(columns=['home_team', 'away_team', 'neutral']))\n",
    "\n",
    "    quarters_results['winner'] = shootout_preds\n",
    "    \n",
    "    quarters_results.loc[quarters_results['home_score'] > quarters_results['away_score'], 'winner'] = quarters_results['home_team']\n",
    "    quarters_results.loc[quarters_results['home_score'] < quarters_results['away_score'], 'winner'] = quarters_results['away_team']\n",
    "    quarters_results.loc[quarters_results['winner'] == 1, 'winner'] = quarters_results['home_team']\n",
    "    quarters_results.loc[quarters_results['winner'] == 0, 'winner'] = quarters_results['away_team']\n",
    "    \n",
    "    winners = list(quarters_results['winner'])\n",
    "    semis = pd.DataFrame(columns=[\"home_team\", \"away_team\"])\n",
    "    semis.loc[0] = sorted([winners[0], winners[1]], key=forced_home_adv)\n",
    "    semis.loc[1] = sorted([winners[2], winners[3]], key=forced_home_adv)\n",
    "    \n",
    "    semis['neutral'] = semis.apply(get_neutral, axis=1)\n",
    "    semis['home_ranking'] = semis.apply(home_rankings, axis=1)\n",
    "    semis['away_ranking'] = semis.apply(away_rankings, axis=1)\n",
    "    \n",
    "    return semis\n",
    "\n",
    "get_semis(model3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final(model):\n",
    "    semis = get_semis(model)\n",
    "    \n",
    "    semis_train = semis.drop(columns=['home_team', 'away_team'])\n",
    "    \n",
    "    preds = np.round(model.predict(semis_train)).astype(int)\n",
    "    preds_df = pd.DataFrame(preds, columns=[\"home_score\", \"away_score\"]).reset_index(drop=True)\n",
    "    \n",
    "    semis_results = pd.concat([semis.reset_index(drop=True), preds_df], axis=1)\n",
    "\n",
    "    shootout_preds = best_model.predict(semis.drop(columns=['home_team', 'away_team', 'neutral']))\n",
    "\n",
    "    semis_results['winner'] = shootout_preds\n",
    "    \n",
    "    semis_results.loc[semis_results['home_score'] > semis_results['away_score'], 'winner'] = semis_results['home_team']\n",
    "    semis_results.loc[semis_results['home_score'] < semis_results['away_score'], 'winner'] = semis_results['away_team']\n",
    "    semis_results.loc[semis_results['winner'] == 1, 'winner'] = semis_results['home_team']\n",
    "    semis_results.loc[semis_results['winner'] == 0, 'winner'] = semis_results['away_team']\n",
    "    \n",
    "    winners = list(semis_results['winner'])\n",
    "    final = pd.DataFrame(columns=[\"home_team\", \"away_team\"])\n",
    "    final.loc[0] = sorted([winners[0], winners[1]], key=forced_home_adv)\n",
    "    final['neutral'] = final.apply(get_neutral, axis=1)\n",
    "    final['home_ranking'] = final.apply(home_rankings, axis=1)\n",
    "    final['away_ranking'] = final.apply(away_rankings, axis=1)\n",
    "    \n",
    "    return final\n",
    "\n",
    "get_final(model3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winner(model):\n",
    "    final = get_final(model)\n",
    "    \n",
    "    final_train = final.drop(columns=['home_team', 'away_team'])\n",
    "    \n",
    "    preds = np.round(model.predict(final_train)).astype(int)\n",
    "    preds_df = pd.DataFrame(preds, columns=[\"home_score\", \"away_score\"]).reset_index(drop=True)\n",
    "    \n",
    "    final_result = pd.concat([final.reset_index(drop=True), preds_df], axis=1)\n",
    "\n",
    "    shootout_preds = best_model.predict(final.drop(columns=['home_team', 'away_team', 'neutral']))\n",
    "\n",
    "    final_result['winner'] = shootout_preds\n",
    "    \n",
    "    final_result.loc[final_result['home_score'] > final_result['away_score'], 'winner'] = final_result['home_team']\n",
    "    final_result.loc[final_result['home_score'] < final_result['away_score'], 'winner'] = final_result['away_team']\n",
    "    final_result.loc[final_result['winner'] == 1, 'winner'] = final_result['home_team']\n",
    "    final_result.loc[final_result['winner'] == 0, 'winner'] = final_result['away_team']\n",
    "    \n",
    "    return final_result['winner'][0]\n",
    "\n",
    "get_winner(model3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = set_3.drop(columns=[\"home_score\", \"away_score\"])\n",
    "# y = set_3[[\"home_score\", \"away_score\"]]\n",
    "\n",
    "# winners = []\n",
    "# n_trials = 100\n",
    "\n",
    "# for i in range(n_trials):\n",
    "#     np.random.seed(i+100)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "#     model3_2 = MultiOutputRegressor(RandomForestRegressor(n_estimators=100))\n",
    "#     model3_2.fit(X_train, y_train)\n",
    "#     winners.append(get_winner(model3_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = sorted(list(set(winners)), key = lambda c: winners.count(c), reverse=True)\n",
    "# y = [winners.count(c) for c in x]\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.bar(x, y)\n",
    "# plt.xlabel('Winner')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = set_3.drop(columns=[\"home_score\", \"away_score\"])\n",
    "# y = set_3[[\"home_score\", \"away_score\"]]\n",
    "\n",
    "# winners = []\n",
    "# n_trials = 100\n",
    "\n",
    "# for i in range(n_trials):\n",
    "#     np.random.seed(i+100)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "#     model3_1 = MultiOutputRegressor(LinearRegression())\n",
    "#     model3_1.fit(X_train, y_train)\n",
    "#     winners.append(get_winner(model3_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = sorted(list(set(winners)), key = lambda c: winners.count(c), reverse=True)\n",
    "# y = [winners.count(c) for c in x]\n",
    "\n",
    "# plt.figure(figsize=(5,5))\n",
    "# plt.bar(x, y)\n",
    "# plt.xlabel('Winner')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "# winners.count(\"Spain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = set_3.drop(columns=[\"home_score\", \"away_score\"])\n",
    "# y = set_3[[\"home_score\", \"away_score\"]]\n",
    "\n",
    "# winners = []\n",
    "# n_trials = 100\n",
    "\n",
    "# for i in range(n_trials):\n",
    "#     np.random.seed(i+100)\n",
    "#     model3_3 = Sequential([\n",
    "#     Dense(64, input_dim=3, activation='relu'), \n",
    "#     Dropout(0.2),  # Dropout layer for regularization\n",
    "#     Dense(128, activation='relu'),  # First hidden layer\n",
    "#     Dropout(0.2),  # Dropout layer for regularization\n",
    "#     Dense(64, activation='relu'),  # Second hidden layer\n",
    "#     Dense(32, activation='relu'),  # Third hidden layer\n",
    "#     Dense(16, activation='relu'),  # Fourth hidden layer\n",
    "#     Dense(2)  # Output layer with 2 neurons (for 2 continuous outcomes)\n",
    "# ])\n",
    "#     model3_3.compile(optimizer='adam', loss='mean_squared_error') \n",
    "#     model3_3.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)  # Validation split for monitoring\n",
    "#     winners.append(get_winner(model3_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = sorted(list(set(winners)), key = lambda c: winners.count(c), reverse=True)\n",
    "# y = [winners.count(c) for c in x]\n",
    "\n",
    "# plt.figure(figsize=(5,5))\n",
    "# plt.bar(x, y)\n",
    "# plt.xlabel('Winner')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()\n",
    "\n",
    "# winners.count(\"Netherlands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "best_model = None\n",
    "best_mse = 1000000\n",
    "n_trials = 100\n",
    "\n",
    "X = set_3.drop(columns=[\"home_score\", \"away_score\"])\n",
    "y = set_3[[\"home_score\", \"away_score\"]]\n",
    "\n",
    "# for _ in range(n_trials):\n",
    "#     np.random.seed(i+100)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "#     model3_2 = MultiOutputRegressor(RandomForestRegressor(n_estimators=100))\n",
    "#     model3_2.fit(X_train, y_train)\n",
    "#     y_pred = model3_2.predict(X_test)\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "#     if mse < best_mse:\n",
    "#         best_mse = mse\n",
    "\n",
    "# best_mse\n",
    "\n",
    "# Define the base model\n",
    "base_model = RandomForestRegressor(n_estimators=200)\n",
    "\n",
    "# Wrap it inside MultiOutputRegressor\n",
    "model = MultiOutputRegressor(base_model)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [100, 200, 300],\n",
    "    'estimator__max_depth': [None, 10, 20],\n",
    "    'estimator__min_samples_split': [2, 5, 10],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4],\n",
    "    'estimator__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Set up the grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "base_model = RandomForestRegressor(n_estimators=500)\n",
    "best_model = MultiOutputRegressor(base_model)\n",
    "\n",
    "\n",
    "X = set_3.drop(columns=[\"home_score\", \"away_score\"])\n",
    "y = set_3[[\"home_score\", \"away_score\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "\n",
    "best_model.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
